# üèóÔ∏è Arquitectura y Funcionalidad de Sandra IA - Extracci√≥n del Workflow

**Fecha:** 2025-01-11  
**Fuente:** Workflow completo de Sandra Studio  
**Estado:** Extracci√≥n t√©cnica completa

---

## üìä RESUMEN EJECUTIVO

### Objetivo del Sistema
Sandra IA es un sistema de inteligencia artificial multimodal, robusto y potente, construido con modelos de c√≥digo abierto (Qwen y DeepSeek), orquestado por 117 subagentes especializados, dise√±ado para funcionar principalmente online v√≠a Groq API con un modelo local ligero para orquestaci√≥n m√≠nima.

---

## üß† ARQUITECTURA DE MODELOS

### Modelos Online (Groq API)

#### 1. Razonamiento Profundo
- **Qwen:** `qwen3-235b-a22b` (Qwen3 MAX, 235B par√°metros, MoE, multimodal)
- **DeepSeek:** `deepseek-r1` (236B par√°metros, MoE, entrenado en 8T tokens)

#### 2. An√°lisis Visual (Multimodal)
- **Qwen:** `qwen-vl-max` (OCR preciso, razonamiento visual, an√°lisis de gr√°ficos, ~32K tokens visuales)
- **DeepSeek:** `deepseek-vl-7b-chat` (detecci√≥n de objetos, escenas complejas)

#### 3. Ejecuci√≥n de C√≥digo
- **Qwen:** `qwen3-235b-a22b` (soporta code generation)
- **DeepSeek:** `deepseek-coder-v2` (generaci√≥n segura, refactorizaci√≥n, tests unitarios)

#### 4. Audio/Voz
- **Qwen:** `qwen-audio-chat` (STT multiling√ºe, TTS natural, an√°lisis emocional de voz)
- **DeepSeek:** No disponible a√∫n

### Modelo Local Ligero (Orquestaci√≥n M√≠nima)
- **Qwen:** `Qwen2.5-1.5B-Instruct-GGUF` (Q4_K_M, ~0.9 GB)
  - Comunicaci√≥n con app
  - Control de subagentes
  - Fallback de bajo nivel
  - Ejecuci√≥n de scripts de control

---

## ‚öôÔ∏è SISTEMA DE ORQUESTACI√ìN

### Principios Fundamentales
1. **Sin Prioridades Est√°ticas:** Ning√∫n modelo tiene prioridad num√©rica sobre otro
2. **Selecci√≥n Din√°mica:** El sistema Auto-Agent decide qu√© modelo usar seg√∫n:
   - Tipo de tarea
   - Especialidad del modelo
   - Historial de √©xito
   - Latencia y disponibilidad
   - Balance de carga
3. **Uso Dual Simult√°neo:** Ambos modelos (Qwen + DeepSeek) est√°n activos simult√°neamente
4. **Asignaci√≥n Funcional:** Cada modelo tiene un `role` que define su funci√≥n en la tarea, no su prioridad

### L√≥gica de Selecci√≥n por Tarea

#### Razonamiento
```javascript
// Siempre devuelve ambos modelos
return [
  { provider: 'groq', model: 'qwen3-235b-a22b', role: 'primary-reasoner' },
  { provider: 'groq', model: 'deepseek-r1', role: 'co-reasoner' }
];
```

#### Visi√≥n
- **Documentos/Texto:** Qwen-VL (OCR) + DeepSeek-VL (an√°lisis de escena)
- **Objetos/Escenas:** DeepSeek-VL (detecci√≥n) + Qwen-VL (contexto)
- **General:** Ambos en paralelo

#### C√≥digo
- **Python/JS/TS:** Qwen3 (dise√±o l√≥gico) + DeepSeek-Coder (implementaci√≥n)
- **Rust/C++/Go:** DeepSeek-Coder (programaci√≥n de sistemas) + Qwen3 (revisi√≥n de seguridad)
- **General:** DeepSeek-Coder (primario) + Qwen3 (secundario)

---

## ü§ñ SISTEMA DE SUBAGENTES (117 Subagentes)

### Arquitectura de Subagentes

#### Nivel 1: Core Agents
- `sandra_core` - N√∫cleo principal
- `mcp_coordinator` - Coordinador MCP
- `galaxy_platform` - Plataforma Galaxy
- `memory_manager` - Gestor de memoria

#### Nivel 2: Business Agents
- `negotiation` - Negociaci√≥n
- `booking` - Reservas
- `payment` - Pagos
- `property` - Propiedades

#### Nivel 3: Communication Agents
- `multimodal` - Multimodal
- `whatsapp` - WhatsApp
- `voice` - Voz
- `avatar` - Avatar

#### Nivel 4: Support Agents
- `training` - Entrenamiento
- `analytics` - An√°lisis
- `security` - Seguridad
- `cache` - Cach√©

### Subagentes Especializados Identificados

#### Monitores
1. `sandra-coo` - Sandra COO (Groq Llama 3.3 70B) - Orquestador principal
2. `sistema-conversacional-analyst` - Analista de Sistemas Conversacionales
3. `conversational-code-reviewer` - Revisor de C√≥digo Conversacional
4. `app-functionality-monitor` - Monitor de Funcionalidad de App
5. `app-performance-monitor` - Monitor de Performance
6. `git-repo-monitor` - Monitor de Repositorio Git

#### Especialistas
1. `claude-code` - Claude Code Assistant (Claude 3.5 Sonnet)
2. `sandra-groq` - Sandra con Super Poderes MCP
3. `deepgram-stt-specialist` - Especialista en Deepgram STT
4. `frontend-audio-specialist` - Especialista en Audio Frontend
5. `frontend-specialist` - Especialista en Frontend
6. `event-handler-specialist` - Especialista en Event Handlers
7. `ui-specialist` - Especialista en UI/UX
8. `code-reviewer` - Revisor de C√≥digo

---

## üîÑ FLUJO DE FUNCIONAMIENTO

### 1. Recepci√≥n de Tarea
- Usuario env√≠a tarea/pregunta
- Sistema Auto-Agent analiza la tarea
- Identifica tipo: reasoning, vision, code, audio

### 2. Selecci√≥n de Modelos
- Sistema selecciona modelos apropiados (siempre 2: Qwen + DeepSeek)
- Asigna roles funcionales a cada modelo
- Verifica disponibilidad y latencia

### 3. Ejecuci√≥n
- **Paralelo:** Ambos modelos procesan simult√°neamente
- **Secuencial:** Un modelo dise√±a, otro implementa
- **Consenso:** Compara salidas y fusiona resultados

### 4. Orquestaci√≥n de Subagentes
- Si requiere especializaci√≥n, invoca subagente apropiado
- Subagente puede usar modelo espec√≠fico seg√∫n su especialidad
- Resultado se integra en respuesta final

### 5. Respuesta
- Sistema fusiona/valida respuestas de ambos modelos
- Presenta resultado unificado al usuario
- Registra m√©tricas de uso y √©xito

---

## üì¶ COMPONENTES DEL SISTEMA

### 1. Orquestador Principal
- **Archivo:** `llm-orchestrator/ai-orchestrator.js`
- **Funci√≥n:** Coordinador central de modelos y subagentes
- **Caracter√≠sticas:**
  - Selecci√≥n din√°mica de modelos
  - Balanceo de carga
  - Gesti√≥n de fallbacks
  - Integraci√≥n con MCP Server

### 2. Sistema de Roles
- **Archivo:** `core/roles-system.js`
- **Funci√≥n:** Asignaci√≥n de modelos seg√∫n rol
- **Caracter√≠sticas:**
  - Mapeo rol ‚Üí modelo
  - Contexto online/offline
  - Especializaci√≥n por dominio

### 3. MCP Server
- **Puerto:** 3141
- **Funci√≥n:** Servidor Model Context Protocol
- **Caracter√≠sticas:**
  - Integraci√≥n con 117 subagentes
  - Invocaci√≥n desde Claude/Cursor
  - Automatizaci√≥n completa

### 4. Configuraci√≥n
- **Archivo:** `config/models.json`
- **Contenido:** Definici√≥n de todos los modelos
- **Formato:** JSON estructurado por categor√≠a

### 5. Health Check
- **Script:** `scripts/health-check.mjs`
- **Funci√≥n:** Verificaci√≥n del sistema
- **Caracter√≠sticas:**
  - Estado de modelos online
  - Verificaci√≥n de subagentes
  - Estado de MCP Server
  - Estado de Avatar (HeyGen + Cartesia)

---

## üîß CONFIGURACI√ìN T√âCNICA

### Variables de Entorno (.env.pro)
```env
# Groq API (para Qwen3 y DeepSeek-R1)
GROQ_API_KEY=tu_groq_api_key
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Audio (Deepgram + Cartesia + HeyGen)
DEEPGRAM_API_KEY=tu_deepgram_api_key
CARTESIA_API_KEY=tu_cartesia_api_key
HEYGEN_API_KEY=tu_heygen_api_key
HEYGEN_AVATAR_ID=tu_avatar_id

# Base de Datos (Neon)
DATABASE_URL=postgresql://...

# Local (llama.cpp para modelos GGUF)
LLAMACPP_SERVER=http://localhost:8080
```

### Estructura de Directorios
```
IA-SANDRA/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ models.json           # Configuraci√≥n de modelos
‚îú‚îÄ‚îÄ llm-orchestrator/
‚îÇ   ‚îî‚îÄ‚îÄ ai-orchestrator.js    # Orquestador principal
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ roles-system.js       # Sistema de roles
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ health-check.mjs      # Verificaci√≥n del sistema
‚îÇ   ‚îî‚îÄ‚îÄ download-models.sh    # Descarga de modelos locales
‚îú‚îÄ‚îÄ models/                   # Modelos locales (GGUF)
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îî‚îÄ‚îÄ subagents-manifest.json  # 117 subagentes
‚îî‚îÄ‚îÄ .env.pro                  # Variables de entorno
```

---

## üéØ FUNCIONALIDADES PRINCIPALES

### 1. Multimodalidad
- **Visi√≥n:** OCR, an√°lisis de im√°genes, detecci√≥n de objetos
- **Audio:** STT, TTS, an√°lisis emocional
- **Texto:** Razonamiento profundo, generaci√≥n de c√≥digo
- **C√≥digo:** Generaci√≥n, refactorizaci√≥n, tests

### 2. Orquestaci√≥n Inteligente
- Selecci√≥n autom√°tica de modelos
- Balanceo de carga
- Fallback autom√°tico
- Paralelizaci√≥n cuando es posible

### 3. Integraci√≥n con Subagentes
- 117 subagentes especializados
- Invocaci√≥n bajo demanda
- Especializaci√≥n por dominio
- Coordinaci√≥n centralizada

### 4. Persistencia y Estado
- Base de datos Neon (PostgreSQL)
- Gesti√≥n de memoria
- Historial de interacciones
- M√©tricas de uso

---

## üìà M√âTRICAS Y MONITOREO

### M√©tricas del Sistema
- **Latencia:** Tiempo de respuesta por modelo
- **Tasa de √âxito:** Porcentaje de tareas completadas correctamente
- **Uso:** Distribuci√≥n de uso entre modelos
- **Disponibilidad:** Estado de modelos online

### Monitoreo Continuo
- Estado de modelos (online/offline)
- Estado de subagentes
- Estado de MCP Server
- Estado de integraciones (Deepgram, HeyGen, Cartesia)

---

## ‚úÖ REQUISITOS T√âCNICOS

### Modelos Online
- Acceso a Groq API
- API Key v√°lida
- Conexi√≥n a internet estable

### Modelo Local
- Espacio en disco: ~1 GB (Qwen2.5-1.5B)
- RAM: ~2 GB m√≠nimo
- CPU: 4+ threads recomendado

### Dependencias
- Node.js 18+
- llama.cpp (para modelos GGUF locales)
- PostgreSQL (Neon)
- APIs de terceros (Deepgram, HeyGen, Cartesia)

---

## üîí LICENCIAS Y LEGALIDAD

### Modelos Qwen
- **Licencia:** Apache 2.0
- **Open Weights:** ‚úÖ S√≠
- **Uso Comercial:** ‚úÖ Permitido
- **Sin Restricciones:** ‚úÖ Sin censura, sin alineamiento occidental

### Modelos DeepSeek
- **Licencia:** MIT / Apache 2.0
- **Open Weights:** ‚úÖ S√≠
- **Uso Comercial:** ‚úÖ Permitido
- **Sin Restricciones:** ‚úÖ Sin censura, sin alineamiento occidental

---

## üìù NOTAS IMPORTANTES

1. **No hay prioridades est√°ticas:** Todos los modelos son iguales en jerarqu√≠a
2. **Selecci√≥n din√°mica:** El sistema decide seg√∫n contexto y tarea
3. **Uso dual:** Siempre se usan ambos modelos (Qwen + DeepSeek) cuando es posible
4. **Local m√≠nimo:** Solo un modelo local ligero para orquestaci√≥n b√°sica
5. **Online primero:** Sistema dise√±ado para funcionar principalmente online
6. **117 subagentes:** Todos disponibles y listos para usar
7. **Sin marginaci√≥n:** Ning√∫n modelo es "backup" o "secundario" por defecto

---

**Fin del Documento de Extracci√≥n**

